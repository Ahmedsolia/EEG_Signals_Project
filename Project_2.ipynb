{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48879a59",
   "metadata": {},
   "source": [
    "# EEG Subject Identification with Channel-Split CNN-RNN\n",
    "\n",
    "This notebook trains a CNN-RNN model to identify the subject from EEG epochs.  \n",
    "It uses **50 channels for training** and evaluates on **14 unseen channels** to test channel generalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c3972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import gc\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv1D, MaxPooling1D, TimeDistributed,\n",
    "    LSTM, Dense, Dropout, BatchNormalization, Reshape\n",
    ")\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "DATA_ROOT = r'/content/drive/MyDrive/EEG' \n",
    "N_SUBJECTS = 109\n",
    "RUN_ID = '04'\n",
    "N_CHANNELS = 64\n",
    "SFREQ = 160.0\n",
    "DOWNSAMPLE_FREQ = 80.0 \n",
    "EPOCH_DURATION_SEC = 4.0\n",
    "N_TIMESTEPS = int(EPOCH_DURATION_SEC * DOWNSAMPLE_FREQ) # 320\n",
    "\n",
    "# --- CLASSIFICATION GOAL ---\n",
    "N_CLASSES = N_SUBJECTS  # Subject ID classification\n",
    "N_CHANNELS_TRAIN = 50\n",
    "N_CHANNELS_TEST = 14\n",
    "CHANNEL_DROPOUT_RATE = 0.2 \n",
    "EVENT_ID = {'T1': 1, 'T2': 2}\n",
    "\n",
    "# Reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e30a32",
   "metadata": {},
   "source": [
    "## CNN-RNN Model with Channel Dropout\n",
    "\n",
    "- **Input:** (N_CHANNELS_TRAIN, N_TIMESTEPS, 1)  \n",
    "- **Channel Dropout:** Improves robustness to missing or noisy channels  \n",
    "- **TimeDistributed Conv1D + MaxPooling:** Extract temporal features for each channel  \n",
    "- **LSTM:** Capture temporal dependencies  \n",
    "- **Dense → Softmax:** Predicts the subject ID among 109 classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ac14db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_rnn_model(input_shape):\n",
    "    \"\"\"CNN-RNN model with Channel Dropout for EEG subject ID classification.\"\"\"\n",
    "    input_layer = Input(shape=input_shape, name='eeg_input')\n",
    "    \n",
    "    x = Dropout(CHANNEL_DROPOUT_RATE, noise_shape=(None, input_shape[0], 1, 1), \n",
    "                name='channel_dropout')(input_layer)\n",
    "\n",
    "    x = TimeDistributed(Conv1D(16, 3, activation='relu', padding='same'), name='td_conv_spatial')(x)\n",
    "    x = TimeDistributed(BatchNormalization(), name='td_bn_1')(x)\n",
    "    x = TimeDistributed(MaxPooling1D(2), name='td_maxpool_temporal')(x)\n",
    "\n",
    "    n_features_combined = input_shape[0] * 16\n",
    "    x = Reshape((N_TIMESTEPS // 2, n_features_combined), name='reshape_for_rnn')(x)\n",
    "\n",
    "    x = LSTM(32, return_sequences=True, name='lstm_1')(x)\n",
    "    x = Dropout(0.5, name='dropout_1')(x)\n",
    "    x = LSTM(16, return_sequences=False, name='lstm_2')(x)\n",
    "\n",
    "    x = Dense(16, activation='relu', name='dense_1')(x)\n",
    "    output_layer = Dense(N_CLASSES, activation='softmax', name='output')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee24451",
   "metadata": {},
   "source": [
    "## Load and Preprocess EEG Data\n",
    "\n",
    "- Load each subject's EDF file using **MNE**\n",
    "- Apply bandpass filter (8–30 Hz)\n",
    "- Downsample to 80 Hz\n",
    "- Epoch into 4-second windows\n",
    "- Handle missing or empty files gracefully\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0089263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data():\n",
    "    all_epochs = []\n",
    "    print(\"Loading and preprocessing data...\")\n",
    "\n",
    "    for sub_idx in range(1, N_SUBJECTS + 1):\n",
    "        sub_str = f'S{sub_idx:03d}'\n",
    "        file_name = f'{sub_str}R{RUN_ID}.edf'\n",
    "        file_path = os.path.join(DATA_ROOT, sub_str, file_name)\n",
    "\n",
    "        try:\n",
    "            raw = mne.io.read_raw_edf(file_path, preload=True, verbose=False)\n",
    "            raw.filter(8., 30., fir_design='firwin', skip_by_annotation='edge', verbose=False)\n",
    "            raw.resample(DOWNSAMPLE_FREQ, npad=\"auto\")\n",
    "\n",
    "            events, _ = mne.events_from_annotations(raw, event_id=EVENT_ID, verbose=False)\n",
    "            epochs = mne.Epochs(raw, events, EVENT_ID, tmin=0., tmax=EPOCH_DURATION_SEC,\n",
    "                                baseline=None, preload=True, verbose=False)\n",
    "            \n",
    "            del raw\n",
    "            gc.collect()\n",
    "\n",
    "            if len(epochs) == 0:\n",
    "                print(f\"Warning: No epochs for subject {sub_idx}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            all_epochs.append(epochs)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file_path}, skipping subject {sub_idx}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error {sub_str}: {e}, skipping.\")\n",
    "\n",
    "    print(f\"\\nEpoching complete. Loaded {len(all_epochs)} subjects.\")\n",
    "    return all_epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48139a7",
   "metadata": {},
   "source": [
    "## Convert Epochs to NumPy Arrays\n",
    "\n",
    "- Concatenate all epochs across subjects\n",
    "- Normalize globally (Z-score)\n",
    "- Labels correspond to **subject ID**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731a7953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data():\n",
    "    all_epochs = []\n",
    "    print(\"Loading and preprocessing data...\")\n",
    "\n",
    "    for sub_idx in range(1, N_SUBJECTS + 1):\n",
    "        sub_str = f'S{sub_idx:03d}'\n",
    "        file_name = f'{sub_str}R{RUN_ID}.edf'\n",
    "        file_path = os.path.join(DATA_ROOT, sub_str, file_name)\n",
    "\n",
    "        try:\n",
    "            raw = mne.io.read_raw_edf(file_path, preload=True, verbose=False)\n",
    "            raw.filter(8., 30., fir_design='firwin', skip_by_annotation='edge', verbose=False)\n",
    "            raw.resample(DOWNSAMPLE_FREQ, npad=\"auto\")\n",
    "\n",
    "            events, _ = mne.events_from_annotations(raw, event_id=EVENT_ID, verbose=False)\n",
    "            epochs = mne.Epochs(raw, events, EVENT_ID, tmin=0., tmax=EPOCH_DURATION_SEC,\n",
    "                                baseline=None, preload=True, verbose=False)\n",
    "            \n",
    "            del raw\n",
    "            gc.collect()\n",
    "\n",
    "            if len(epochs) == 0:\n",
    "                print(f\"Warning: No epochs for subject {sub_idx}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            all_epochs.append(epochs)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file_path}, skipping subject {sub_idx}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error {sub_str}: {e}, skipping.\")\n",
    "\n",
    "    print(f\"\\nEpoching complete. Loaded {len(all_epochs)} subjects.\")\n",
    "    return all_epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8237e25",
   "metadata": {},
   "source": [
    "## Channel-Split Training and Evaluation\n",
    "\n",
    "- Randomly select **50 channels for training**  \n",
    "- Reserve **14 channels for testing**\n",
    "- Test data is **padded to match model input**  \n",
    "- Evaluate **subject identification accuracy** on unseen channels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0210c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_channel_split_subject_id(X, Y):\n",
    "    N_TOTAL_CHANNELS = X.shape[1]\n",
    "    \n",
    "    if N_TOTAL_CHANNELS != N_CHANNELS:\n",
    "        print(f\"Error: Expected {N_CHANNELS} channels, found {N_TOTAL_CHANNELS}. Aborting.\")\n",
    "        return 0.0\n",
    "    \n",
    "    channel_indices = np.arange(N_TOTAL_CHANNELS)\n",
    "    np.random.shuffle(channel_indices)\n",
    "    \n",
    "    train_channels_idx = channel_indices[:N_CHANNELS_TRAIN]\n",
    "    test_channels_idx = channel_indices[N_CHANNELS_TRAIN:]\n",
    "    \n",
    "    X_train_data = X[:, train_channels_idx, :, :]\n",
    "    X_test_data = X[:, test_channels_idx, :, :]\n",
    "    \n",
    "    input_shape = X_train_data.shape[1:] \n",
    "    model = create_cnn_rnn_model(input_shape)\n",
    "    \n",
    "    print(f\"\\n--- Training Model on {N_CHANNELS_TRAIN} Channels ---\")\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_data, Y,\n",
    "        epochs=10,\n",
    "        batch_size=8,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    N_EPOCHS = X.shape[0]\n",
    "    X_test_padded = np.zeros(X_train_data.shape, dtype=X.dtype)\n",
    "    X_test_padded[:, :N_CHANNELS_TEST, :, :] = X_test_data\n",
    "\n",
    "    print(f\"\\n--- Evaluating Model on {N_CHANNELS_TEST} Unseen Channels ---\")\n",
    "    loss_test, acc_test = model.evaluate(X_test_padded, Y, verbose=0)\n",
    "    \n",
    "    print(f\"Classification Accuracy (14 Unseen Channels): {acc_test:.4f}\")\n",
    "    \n",
    "    K.clear_session()\n",
    "    del model\n",
    "    gc.collect()\n",
    "\n",
    "    return acc_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee66111",
   "metadata": {},
   "source": [
    "## Main Execution\n",
    "\n",
    "1. Load EEG data  \n",
    "2. Convert to NumPy arrays  \n",
    "3. Train model on 50 channels  \n",
    "4. Evaluate on 14 unseen channels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c473f69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MAIN ---\n",
    "all_epochs = load_and_preprocess_data()\n",
    "\n",
    "if all_epochs:\n",
    "    X, Y, S = convert_epochs_to_numpy(all_epochs)\n",
    "    \n",
    "    final_acc = train_channel_split_subject_id(X, Y)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"FINAL SUBJECT ID ACCURACY (Train {N_CHANNELS_TRAIN} / Test {N_CHANNELS_TEST}): {final_acc:.4f}\")\n",
    "    print(\"=\"*50)\n",
    "else:\n",
    "    print(\"No data available for training.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
