{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25b9d053",
   "metadata": {},
   "source": [
    "## üì¶ Imports & Configuration\n",
    "\n",
    "This cell sets up the environment for the EEG classification project. It imports all the necessary libraries for data handling, preprocessing, visualization, and deep learning. Additionally, it defines key configuration parameters such as the number of subjects, EEG channels, sampling frequency, epoch duration, number of classes, batch size, and cross-validation splits. These settings ensure that the data and model are processed consistently throughout the workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55753a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv1D, MaxPooling1D, TimeDistributed,\n",
    "    LSTM, Dense, Dropout, BatchNormalization, Reshape, Permute\n",
    ")\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "N_SUBJECTS = 109\n",
    "RUN_ID = '04'  # Left vs Right Fist\n",
    "N_CHANNELS = 64\n",
    "SFREQ = 160.0\n",
    "DOWNSAMPLE_FREQ = 80.0\n",
    "EPOCH_DURATION_SEC = 4.0\n",
    "N_TIMESTEPS = int(EPOCH_DURATION_SEC * DOWNSAMPLE_FREQ)\n",
    "N_CLASSES = 2\n",
    "EVENT_ID = {'T1': 1, 'T2': 2}\n",
    "BATCH_SIZE = 64\n",
    "KFOLD_SPLITS = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47176bac",
   "metadata": {},
   "source": [
    "## üß† EEG Classifier Model Definition\n",
    "\n",
    "This cell defines a deep learning model for EEG classification. The model combines convolutional and recurrent layers to capture both spatial and temporal patterns in the EEG signals:\n",
    "\n",
    "- **Input & Dropout:** Accepts EEG data with the specified shape and applies initial dropout for regularization.  \n",
    "- **CNN Block:** Extracts spatial features from each time step using 1D convolutions, batch normalization, and max pooling.  \n",
    "- **Reshape & Permute:** Prepares the data for the recurrent layers by rearranging and flattening the spatial dimensions.  \n",
    "- **LSTM Block:** Captures temporal dependencies in the EEG signal using stacked LSTM layers with dropout for regularization.  \n",
    "- **Dense Layers & Output:** Processes features through a fully connected layer and outputs class probabilities via a softmax layer.\n",
    "\n",
    "This architecture is designed to effectively combine spatial and temporal information for motor imagery EEG classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d64ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier_model(input_shape=(N_CHANNELS, N_TIMESTEPS, 1)):\n",
    "    input_layer = Input(shape=input_shape, name='eeg_input')\n",
    "    x = Dropout(0.2)(input_layer)\n",
    "\n",
    "    # CNN Block\n",
    "    x = TimeDistributed(Conv1D(16, 3, activation='relu', padding='same'))(x)\n",
    "    x = TimeDistributed(BatchNormalization())(x)\n",
    "    x = TimeDistributed(MaxPooling1D(2))(x)\n",
    "\n",
    "    # Permute for RNN\n",
    "    x = Permute((2, 1, 3))(x)\n",
    "    x = Reshape((-1, N_CHANNELS * 16))(x)\n",
    "\n",
    "    # LSTM Block\n",
    "    x = LSTM(32, return_sequences=True)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = LSTM(16, return_sequences=False)(x)\n",
    "\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    output_layer = Dense(N_CLASSES, activation='softmax')(x)\n",
    "\n",
    "    return Model(inputs=input_layer, outputs=output_layer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d1fef8",
   "metadata": {},
   "source": [
    "## üì• Loading and Preprocessing EEG Data\n",
    "\n",
    "This cell defines a function to load EEG data from all 109 subjects and preprocess it for model training. \n",
    "\n",
    "Key steps include:\n",
    "\n",
    "- **Data Loading:** Reads each subject's EDF file for the selected motor imagery task.  \n",
    "- **Filtering & Resampling:** Band-pass filters the EEG signals (8‚Äì30 Hz) and downsamples them to the target frequency.  \n",
    "- **Epoching:** Segments continuous EEG into fixed-length epochs corresponding to the task events.  \n",
    "- **Length Adjustment:** Ensures all epochs have the same number of time points, padding or truncating as necessary.  \n",
    "- **Normalization:** Applies per-channel z-score normalization to standardize the signals.  \n",
    "- **Data Aggregation:** Combines all subjects‚Äô data into single arrays for features (`X`) and labels (`Y`) and adds a channel dimension for the model input.  \n",
    "\n",
    "This function returns preprocessed EEG data ready for training the deep learning classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3dd91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_109_subjects():\n",
    "    X_list, Y_list = [], []\n",
    "    print(f\"Starting Data Load for {N_SUBJECTS} Subjects...\")\n",
    "    RAW_DATA_PATH = r'/content/drive/MyDrive/EEG'\n",
    "\n",
    "    for sub_idx in range(1, N_SUBJECTS + 1):\n",
    "        sub_str = f'S{sub_idx:03d}'\n",
    "        file_path = os.path.join(RAW_DATA_PATH, sub_str, f'{sub_str}R{RUN_ID}.edf')\n",
    "\n",
    "        try:\n",
    "            raw = mne.io.read_raw_edf(file_path, preload=True, verbose=False)\n",
    "            raw.filter(8., 30., fir_design='firwin', skip_by_annotation='edge', verbose=False)\n",
    "            raw.resample(DOWNSAMPLE_FREQ, npad=\"auto\")\n",
    "\n",
    "            events, _ = mne.events_from_annotations(raw, event_id=EVENT_ID, verbose=False)\n",
    "            epochs = mne.Epochs(raw, events, EVENT_ID, tmin=0., tmax=EPOCH_DURATION_SEC,\n",
    "                                baseline=None, preload=True, verbose=False)\n",
    "\n",
    "            data = epochs.get_data(units='uV')\n",
    "\n",
    "            # Fix variable lengths\n",
    "            if data.shape[2] > N_TIMESTEPS:\n",
    "                data = data[:, :, :N_TIMESTEPS]\n",
    "            elif data.shape[2] < N_TIMESTEPS:\n",
    "                pad_width = N_TIMESTEPS - data.shape[2]\n",
    "                data = np.pad(data, ((0,0),(0,0),(0, pad_width)), mode='constant')\n",
    "\n",
    "            # Per-channel normalization\n",
    "            for i in range(len(data)):\n",
    "                mean = np.mean(data[i], axis=1, keepdims=True)\n",
    "                std = np.std(data[i], axis=1, keepdims=True)\n",
    "                data[i] = (data[i] - mean) / (std + 1e-6)\n",
    "\n",
    "            X_list.append(data.astype('float32'))\n",
    "            Y_list.append(epochs.events[:, 2] - 1)\n",
    "\n",
    "            del raw, epochs, data\n",
    "            gc.collect()\n",
    "\n",
    "            if sub_idx % 10 == 0:\n",
    "                print(f\" -> Loaded {sub_idx} subjects...\")\n",
    "\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    if not X_list:\n",
    "        return None, None\n",
    "\n",
    "    X_pool = np.concatenate(X_list, axis=0)\n",
    "    Y_pool = np.concatenate(Y_list, axis=0)\n",
    "    X_pool = np.expand_dims(X_pool, axis=-1)\n",
    "\n",
    "    print(f\"Total Epochs: {X_pool.shape[0]}\")\n",
    "    return X_pool, Y_pool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0c3020",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Training the Universal EEG Classifier\n",
    "\n",
    "This cell defines a function to train the EEG classifier using stratified K-Fold cross-validation. \n",
    "\n",
    "Key steps include:\n",
    "\n",
    "- **K-Fold Splitting:** Divides the dataset into training and testing folds while preserving class balance.  \n",
    "- **Model Creation & Compilation:** Initializes the CNN-LSTM model and compiles it with the Adam optimizer and sparse categorical cross-entropy loss.  \n",
    "- **Training with Callbacks:** Trains the model on each fold with early stopping and learning rate reduction to prevent overfitting and improve convergence.  \n",
    "- **Evaluation:** Measures fold accuracy on the test set and displays a confusion matrix to visualize classification performance.  \n",
    "- **Aggregation:** After all folds, calculates the mean accuracy across folds as an overall performance metric.\n",
    "\n",
    "This approach ensures robust evaluation and leverages all available data for training the universal classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b53d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_universal_classifier(X, Y):\n",
    "    skf = StratifiedKFold(n_splits=KFOLD_SPLITS, shuffle=True, random_state=42)\n",
    "    fold_accuracies = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, Y)):\n",
    "        print(f\"\\n{'='*20} FOLD {fold+1}/{KFOLD_SPLITS} {'='*20}\")\n",
    "\n",
    "        X_train, Y_train = X[train_idx], Y[train_idx]\n",
    "        X_test, Y_test = X[test_idx], Y[test_idx]\n",
    "\n",
    "        K.clear_session()\n",
    "        model = create_classifier_model()\n",
    "\n",
    "        optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "\n",
    "        model.fit(\n",
    "            X_train, Y_train,\n",
    "            epochs=30,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            validation_data=(X_test, Y_test),\n",
    "            callbacks=[early_stop, reduce_lr],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        loss, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "        fold_accuracies.append(acc)\n",
    "        print(f\"Fold {fold+1} Accuracy: {acc:.4f}\")\n",
    "\n",
    "        # Confusion matrix\n",
    "        Y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "        cm = confusion_matrix(Y_test, Y_pred)\n",
    "        plt.figure(figsize=(4, 3))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'Fold {fold+1}')\n",
    "        plt.show()\n",
    "\n",
    "        del model\n",
    "        gc.collect()\n",
    "\n",
    "    print(f\"FINAL MEAN ACCURACY: {np.mean(fold_accuracies):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ef80f0",
   "metadata": {},
   "source": [
    "## üöÄ Running the Full Pipeline\n",
    "\n",
    "This cell executes the complete EEG classification workflow:\n",
    "\n",
    "1. **Data Loading & Preprocessing:** Calls the function to load and preprocess EEG data from all 109 subjects.  \n",
    "2. **Model Training & Evaluation:** If the data is successfully loaded, it trains the universal EEG classifier using stratified K-Fold cross-validation and evaluates its performance on each fold.\n",
    "\n",
    "Effectively, this cell ties together all previous steps to produce a trained model and report its accuracy across the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4c9870",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pool, Y_pool = load_all_109_subjects()\n",
    "if X_pool is not None:\n",
    "    train_universal_classifier(X_pool, Y_pool)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
